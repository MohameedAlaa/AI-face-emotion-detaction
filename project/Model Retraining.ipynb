{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02033d48",
   "metadata": {},
   "source": [
    "# ü§ñ AI Face Emotion Detection - Model Retraining\n",
    "\n",
    "This notebook retrains the emotion detection model using user feedback data collected from the app.\n",
    "\n",
    "## Workflow:\n",
    "1. **Load Feedback Data** - From CSV and images\n",
    "2. **Visualize Data** - Check what was corrected\n",
    "3. **Fine-tune Model** - Retrain with feedback\n",
    "4. **Evaluate Performance** - Compare old vs new\n",
    "5. **Update Model** - Replace original with improved version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f957b3",
   "metadata": {},
   "source": [
    "## üìÅ Configuration\n",
    "\n",
    "Set up paths and emotion labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b200b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "FEEDBACK_CSV = os.path.join(BASE_DIR, \"feedback_log.csv\")\n",
    "FEEDBACK_IMAGES_DIR = os.path.join(BASE_DIR, \"feedback_images\")\n",
    "MODEL_PATH = os.path.join(BASE_DIR, \"best_emotion_model.keras\")\n",
    "RETRAINED_MODEL_PATH = os.path.join(BASE_DIR, \"best_emotion_model_retrained.keras\")\n",
    "\n",
    "EMOTION_LABELS = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "print(f\"üìÇ Feedback CSV: {FEEDBACK_CSV}\")\n",
    "print(f\"üìÇ Images Directory: {FEEDBACK_IMAGES_DIR}\")\n",
    "print(f\"üìÇ Model Path: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978d723",
   "metadata": {},
   "source": [
    "## üìä Load & Analyze Feedback Data\n",
    "\n",
    "Load the feedback data and visualize what users corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feedback CSV\n",
    "if not os.path.exists(FEEDBACK_CSV):\n",
    "    print(\"‚ùå No feedback data found. Run the app first to collect feedback.\")\n",
    "else:\n",
    "    df = pd.read_csv(FEEDBACK_CSV)\n",
    "    \n",
    "    # Clean data\n",
    "    df = df.dropna(subset=['image_path', 'corrected_emotion'])\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(df)} feedback records\\n\")\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259c50c",
   "metadata": {},
   "source": [
    "### üìà Visualize Feedback Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5a91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feedback statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Predicted vs Corrected Emotions\n",
    "ax1 = axes[0, 0]\n",
    "emotion_counts = df['corrected_emotion'].value_counts()\n",
    "emotion_counts.plot(kind='bar', ax=ax1, color='skyblue', edgecolor='black')\n",
    "ax1.set_title('Corrected Emotion Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Emotion', fontsize=12)\n",
    "ax1.set_ylabel('Count', fontsize=12)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Correction matrix (predicted -> corrected)\n",
    "ax2 = axes[0, 1]\n",
    "correction_matrix = pd.crosstab(df['predicted_emotion'], df['corrected_emotion'])\n",
    "sns.heatmap(correction_matrix, annot=True, fmt='d', cmap='YlOrRd', ax=ax2, cbar_kws={'label': 'Count'})\n",
    "ax2.set_title('Prediction Correction Matrix', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Corrected Emotion', fontsize=12)\n",
    "ax2.set_ylabel('Predicted Emotion', fontsize=12)\n",
    "\n",
    "# 3. Confidence distribution\n",
    "ax3 = axes[1, 0]\n",
    "df['confidence'].hist(bins=20, ax=ax3, color='lightgreen', edgecolor='black')\n",
    "ax3.set_title('Confidence Score Distribution', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Confidence', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "ax3.axvline(df['confidence'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"confidence\"].mean():.2f}')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Feedbacks over time\n",
    "ax4 = axes[1, 1]\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.groupby(df['timestamp'].dt.date).size().plot(kind='line', marker='o', ax=ax4, color='purple')\n",
    "ax4.set_title('Feedback Collection Over Time', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Date', fontsize=12)\n",
    "ax4.set_ylabel('Number of Feedbacks', fontsize=12)\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Summary Statistics:\")\n",
    "print(f\"   Total feedbacks: {len(df)}\")\n",
    "print(f\"   Average confidence: {df['confidence'].mean():.4f}\")\n",
    "print(f\"   Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec4ba6",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Display Sample Feedback Images\n",
    "\n",
    "View some of the images that were corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample feedback images\n",
    "num_samples = min(6, len(df))\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(num_samples):\n",
    "    row = df.iloc[idx]\n",
    "    image_path = os.path.join(FEEDBACK_IMAGES_DIR, row['image_path'])\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        axes[idx].imshow(img, cmap='gray')\n",
    "        axes[idx].set_title(f\"Predicted: {row['predicted_emotion']}\\nCorrected: {row['corrected_emotion']}\", \n",
    "                           fontsize=10, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "    else:\n",
    "        axes[idx].text(0.5, 0.5, 'Image Not Found', ha='center', va='center')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(num_samples, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66e8b95",
   "metadata": {},
   "source": [
    "## üîÑ Load Feedback Data for Training\n",
    "\n",
    "Prepare images and labels for model retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a208dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feedback data\n",
    "X = []  # Images\n",
    "y = []  # Labels\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_filename = str(row['image_path']).strip()\n",
    "    correct_emotion = str(row['corrected_emotion']).strip()\n",
    "    \n",
    "    image_path = os.path.join(FEEDBACK_IMAGES_DIR, image_filename)\n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        # Load image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = img / 255.0  # Normalize\n",
    "            X.append(img)\n",
    "            y.append(EMOTION_LABELS.index(correct_emotion))\n",
    "            print(f\"  ‚úÖ Loaded: {image_filename} ‚Üí {correct_emotion}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Failed to load: {image_filename}\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå Image not found: {image_path}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshape for model input (batch, height, width, channels)\n",
    "X = X.reshape(-1, 48, 48, 1)\n",
    "\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"   Total samples: {len(X)}\")\n",
    "print(f\"   Shape: {X.shape}\")\n",
    "print(f\"   Labels shape: {y.shape}\")\n",
    "print(f\"   Min/Max pixel values: {X.min():.2f} / {X.max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2710b2",
   "metadata": {},
   "source": [
    "## üß† Load Original Model\n",
    "\n",
    "Load the current model that will be fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original model\n",
    "print(\"üîÑ Loading original model...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "print(\"\\nüìà Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce96387",
   "metadata": {},
   "source": [
    "## üöÄ Fine-Tune Model with Feedback Data\n",
    "\n",
    "Retrain the model with data augmentation to improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34204b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model with lower learning rate for fine-tuning\n",
    "optimizer = Adam(learning_rate=0.0001)  # Lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Data augmentation to improve generalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting fine-tuning...\")\n",
    "print(f\"   Epochs: 10\")\n",
    "print(f\"   Batch size: 8\")\n",
    "print(f\"   Samples: {len(X)}\")\n",
    "print(f\"   Learning rate: 0.0001\\n\")\n",
    "\n",
    "# Fine-tune with the feedback data\n",
    "history = model.fit(\n",
    "    datagen.flow(X, y, batch_size=8),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    steps_per_epoch=max(1, len(X) // 8)\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd838cc",
   "metadata": {},
   "source": [
    "## üìä Visualize Training Results\n",
    "\n",
    "Plot the training loss and accuracy curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history.history['loss'], marker='o', linewidth=2, color='red')\n",
    "ax1.set_title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2 = axes[1]\n",
    "ax2.plot(history.history['accuracy'], marker='o', linewidth=2, color='green')\n",
    "ax2.set_title('Training Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Final Training Results:\")\n",
    "print(f\"   Final Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"   Final Accuracy: {history.history['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df166e",
   "metadata": {},
   "source": [
    "## üíæ Save Retrained Model\n",
    "\n",
    "Save the improved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381dfedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the retrained model\n",
    "model.save(RETRAINED_MODEL_PATH)\n",
    "print(f\"‚úÖ Retrained model saved to:\\n   {RETRAINED_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81723d4",
   "metadata": {},
   "source": [
    "## üîÑ Replace Original Model (Optional)\n",
    "\n",
    "This will backup the old model and replace it with the new one.\n",
    "\n",
    "**‚ö†Ô∏è Warning:** This will update the model used by your Streamlit app!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dd78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup and replace original model\n",
    "import shutil\n",
    "\n",
    "REPLACE_MODEL = True  # Set to True to replace, False to keep original\n",
    "\n",
    "if REPLACE_MODEL:\n",
    "    backup_path = os.path.join(BASE_DIR, \"best_emotion_model_backup.keras\")\n",
    "    \n",
    "    if os.path.exists(RETRAINED_MODEL_PATH):\n",
    "        # Backup original model\n",
    "        if os.path.exists(MODEL_PATH):\n",
    "            shutil.copy(MODEL_PATH, backup_path)\n",
    "            print(f\"üíæ Original model backed up to:\\n   {backup_path}\")\n",
    "        \n",
    "        # Replace with retrained model\n",
    "        shutil.copy(RETRAINED_MODEL_PATH, MODEL_PATH)\n",
    "        print(f\"\\n‚ú® Model updated successfully!\")\n",
    "        print(f\"   New model: {MODEL_PATH}\")\n",
    "        print(f\"\\n‚úÖ Your app will now use the improved model!\")\n",
    "    else:\n",
    "        print(\"‚ùå Retrained model not found!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Original model unchanged.\")\n",
    "    print(f\"   Retrained model saved as: {RETRAINED_MODEL_PATH}\")\n",
    "    print(\"\\n   Set REPLACE_MODEL = True to update the active model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b600f5",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "### What We Did:\n",
    "1. ‚úÖ Loaded {len(df)} feedback records from users\n",
    "2. ‚úÖ Visualized correction patterns and statistics\n",
    "3. ‚úÖ Fine-tuned the model with feedback data\n",
    "4. ‚úÖ Saved the improved model\n",
    "\n",
    "### Next Steps:\n",
    "1. Run your Streamlit app to test the improved model\n",
    "2. Continue collecting feedback to further improve accuracy\n",
    "3. Retrain periodically (weekly/monthly) as more feedback accumulates\n",
    "\n",
    "### Model Files:\n",
    "- **best_emotion_model.keras** - Active model (used by app)\n",
    "- **best_emotion_model_backup.keras** - Previous version\n",
    "- **best_emotion_model_retrained.keras** - Latest retrained version\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Happy Training!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
